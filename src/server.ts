import {WebSocketServer, WebSocket} from "ws";
import {Writable} from "stream";
import * as fs from "fs";
import * as ffmpeg from "fluent-ffmpeg";
import {OpenAI} from "openai";
import {SpeechClient} from "@google-cloud/speech";

const PORT = process.env.PORT ?? 9999;
const TEMP_FILE = "temp.raw";
const OUTPUT_MP3_FILE = "output.mp3";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});
const speechClient = new SpeechClient();

// WebSocketã‚µãƒ¼ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
const wss = new WebSocketServer({port: Number(PORT)});
console.log(`WebSocket server running on ws://localhost:${PORT}`);

wss.on("connection", (ws: WebSocket) => {
  console.log("Client connected");

  // Speech-to-Textã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
  const request = {
    config: {
      encoding: "LINEAR16" as const, // PCMå½¢å¼ï¼ˆ16ãƒ“ãƒƒãƒˆãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰
      sampleRateHertz: 44100, // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒé€ä¿¡ã™ã‚‹éŸ³å£°ã«åˆã‚ã›ã‚‹)
      languageCode: "ja-JP", // æ—¥æœ¬èªž
    },
    interimResults: true, // ä¸­é–“çµæžœã‚’å–å¾—ã™ã‚‹ã‹ã©ã†ã‹
  };

  const recognizeStream = speechClient
    .streamingRecognize(request)
    .on("data", (data) => {
      const transcription = data.results
        ?.map((result) => result.alternatives?.[0].transcript)
        .join("\n");
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›
      console.log(`Transcription: ${transcription}`);
    })
    .on("error", (error) => {
      console.error("Speech-to-Text error:", error);
    });

  // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆ
  const tempFileStream = fs.createWriteStream(TEMP_FILE);
  const audioStream = new Writable({
    write(chunk: Buffer, encoding: string, callback: () => void) {
      recognizeStream.write(chunk);
      tempFileStream.write(chunk); // TEMP_FILEã«æ›¸ãè¾¼ã‚€
      callback();
    },
  });

  // WebSocketã§å—ä¿¡ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’audioStreamã«æµã™
  ws.on("message", (message) => {
    if (Buffer.isBuffer(message)) {
      audioStream.write(message);
    }
  });

  ws.on("close", () => {
    console.log("Client disconnected");
    audioStream.end();
    recognizeStream.end();
    tempFileStream.end(); // TEMP_FILEã®æ›¸ãè¾¼ã¿ã‚’çµ‚äº†
  });

  ws.on("error", (error) => {
    console.error("WebSocket error:", error);
  });

  // TEMP_FILEã®æ›¸ãè¾¼ã¿çµ‚äº†å¾Œã«MP3å¤‰æ›ã‚’é–‹å§‹
  tempFileStream.on("finish", () => {
    console.log("TEMP_FILE write completed. Starting MP3 conversion...");
    encodeToMp3(TEMP_FILE, OUTPUT_MP3_FILE);
  });
});

/**
 * rawãƒ•ã‚¡ã‚¤ãƒ«ã‚’mp3ã«å¤‰æ›
 */
const encodeToMp3 = (rawPath: string, outputPath: string) => {
  ffmpeg(rawPath)
    .inputOptions("-f s16le") // PCMå½¢å¼ï¼ˆ16ãƒ“ãƒƒãƒˆãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰
    .inputOptions("-ar 44100") // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ 16kHz
    .inputOptions("-ac 1") // ãƒ¢ãƒŽãƒ©ãƒ«
    .audioCodec("libmp3lame") // MP3ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    .audioBitrate("192k") // æŽ¨å¥¨å€¤: 128kä»¥ä¸Š
    .output(outputPath)
    .on("end", () => {
      console.log(`MP3 file created: ${outputPath}`);
      // å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
      // fs.unlinkSync(rawPath);
    })
    .on("error", (err) => {
      console.error("Error during MP3 conversion:", err);
    })
    .run();
};

// encodeToMp3(TEMP_FILE, "./output-test2.mp3");

/**
 * éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
 */
const audioToText = async (audioPath: string) => {
  try {
    console.log(`ðŸš€ Start audioToText: ${audioPath}`);
    const response = await openai.audio.transcriptions.create({
      model: "whisper-1",
      file: fs.createReadStream(audioPath),
      language: "ja",
      response_format: "verbose_json",
    });
    console.log(response);
    const outputPath = "./transcription_result.json";
    fs.writeFileSync(outputPath, JSON.stringify(response, null, 2), "utf-8");
    console.log(`âœ… Transcription saved to ${outputPath}`);
  } catch (error) {
    console.error(
      "Error during transcription:",
      error.response?.data || error.message
    );
  }
};

// audioToText("./output.mp3");
