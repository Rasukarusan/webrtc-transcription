import { WebSocketServer, WebSocket } from "ws";
import { Writable } from "stream";
import { SpeechClient } from "@google-cloud/speech";
import * as fs from "fs";
import * as ffmpeg from "fluent-ffmpeg";
import { OpenAI } from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Google Speech-to-Textã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
const speechClient = new SpeechClient();
const requestConfig = {
  config: {
    encoding: "LINEAR16" as const,
    sampleRateHertz: 16000,
    languageCode: "ja-JP", // æ—¥æœ¬èªž
  },
  interimResults: true, // ä¸­é–“çµæžœã‚’å–å¾—
};

const PORT = 9999;
const TEMP_FILE = "temp.raw";
const OUTPUT_MP3_FILE = "output.mp3";

// WebSocketã‚µãƒ¼ãƒãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
const wss = new WebSocketServer({ port: PORT });
console.log(`WebSocket server running on ws://localhost:${PORT}`);

wss.on("connection", (ws: WebSocket) => {
  console.log("Client connected");

  // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆ
  const tempFileStream = fs.createWriteStream(TEMP_FILE);

  // Google Speech-to-Textã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆ
  // const recognizeStream = speechClient.streamingRecognize(requestConfig)
  //   .on('data', data => {
  //     const transcription = data.results[0]?.alternatives[0]?.transcript || '';
  //     console.log(`Transcription: ${transcription}`);
  //   })
  //   .on('error', error => console.error('Speech-to-Text error:', error))
  //   .on('end', () => console.log('Speech-to-Text stream ended'));

  // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’Google Speech-to-Textã¨TEMP_FILEã«æ›¸ãè¾¼ã‚€
  const audioStream = new Writable({
    write(chunk: Buffer, encoding: string, callback: () => void) {
      // recognizeStream.write(chunk); // Speech-to-Textã«é€ä¿¡
      tempFileStream.write(chunk); // TEMP_FILEã«æ›¸ãè¾¼ã‚€
      callback();
    },
  });

  // WebSocketã§å—ä¿¡ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’audioStreamã«æµã™
  ws.on("message", (message) => {
    if (Buffer.isBuffer(message)) {
      audioStream.write(message);
    }
  });

  // TEMP_FILEã®æ›¸ãè¾¼ã¿çµ‚äº†å¾Œã«MP3å¤‰æ›ã‚’é–‹å§‹
  tempFileStream.on("finish", () => {
    console.log("TEMP_FILE write completed. Starting MP3 conversion...");
    encodeToMp3(TEMP_FILE, OUTPUT_MP3_FILE);
  });

  ws.on("close", () => {
    console.log("Client disconnected");
    audioStream.end();
    tempFileStream.end(); // TEMP_FILEã®æ›¸ãè¾¼ã¿ã‚’çµ‚äº†
    // recognizeStream.end(); // Speech-to-Textã®çµ‚äº†
  });

  ws.on("error", (error) => {
    console.error("WebSocket error:", error);
  });
});

/**
 * rawãƒ•ã‚¡ã‚¤ãƒ«ã‚’mp3ã«å¤‰æ›
 */
const encodeToMp3 = (rawPath: string, outputPath: string) => {
  ffmpeg(rawPath)
    .inputOptions("-f s16le") // PCMå½¢å¼ï¼ˆ16ãƒ“ãƒƒãƒˆãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ï¼‰
    .inputOptions("-ar 44100") // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ 16kHz
    .inputOptions("-ac 1") // ãƒ¢ãƒŽãƒ©ãƒ«
    .audioCodec("libmp3lame") // MP3ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    .audioBitrate("192k") // æŽ¨å¥¨å€¤: 128kä»¥ä¸Š
    .output(outputPath)
    .on("end", () => {
      console.log(`MP3 file created: ${outputPath}`);
      // å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
      // fs.unlinkSync(rawPath);
    })
    .on("error", (err) => {
      console.error("Error during MP3 conversion:", err);
    })
    .run();
};

// encodeToMp3(TEMP_FILE, "./output-test.mp3");

/**
 * éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
 */
const audioToText = async (audioPath: string) => {
  try {
    console.log(`ðŸš€ Start audioToText: ${audioPath}`);
    const response = await openai.audio.transcriptions.create({
      model: "whisper-1",
      file: fs.createReadStream(audioPath),
      language: "ja",
      response_format: "verbose_json",
    });
    console.log(response);
    const outputPath = "./transcription_result.json";
    fs.writeFileSync(outputPath, JSON.stringify(response, null, 2), "utf-8");
    console.log(`âœ… Transcription saved to ${outputPath}`);
  } catch (error) {
    console.error(
      "Error during transcription:",
      error.response?.data || error.message
    );
  }
};

// audioToText("./output.mp3");
